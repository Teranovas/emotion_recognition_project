import traceback
import cv2
import mediapipe as mp
import numpy as np
import sys
import os
import glob
from PIL import ImageFont, ImageDraw, Image
from collections import Counter

# ìƒìœ„ ë””ë ‰í† ë¦¬ ëª¨ë“ˆ ë¶ˆëŸ¬ì˜¤ê¸° ì„¤ì •
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from model.infer import predict_emotion
from python.recorder import EmotionLogger
from python.cpp_bridge import send_emotion_to_cpp, get_emotion_stats_from_cpp, reset_cpp_stats
from python.visualizer import plot_emotion_bar_chart, plot_emotion_trend

def run_face_detection():
    mp_face_detection = mp.solutions.face_detection
    mp_drawing = mp.solutions.drawing_utils
    logger = EmotionLogger()
    emotion_counter = Counter()

    # âœ… Macìš© í•œê¸€ í°íŠ¸ ê²½ë¡œ
    font_path = "/System/Library/Fonts/Supplemental/AppleGothic.ttf"
    font = ImageFont.truetype(font_path, 28)

    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:
        cap = cv2.VideoCapture(1)  # í•„ìš” ì‹œ ì¸ë±ìŠ¤ ì¡°ì •

        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("ğŸ¥ ì–¼êµ´ ì¸ì‹ ë° ê°ì • ë¶„ì„ ì‹œì‘ (ESC í‚¤ë¡œ ì¢…ë£Œ)")

        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                break

            image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_detection.process(image_rgb)
            image_bgr = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2BGR)

            # PIL ì´ë¯¸ì§€ ë³€í™˜ (í•œê¸€ ë¼ë²¨ìš©)
            image_pil = Image.fromarray(image_bgr)
            draw = ImageDraw.Draw(image_pil)

            if results.detections:
                for detection in results.detections:
                    mp_drawing.draw_detection(image_bgr, detection)

                    bbox = detection.location_data.relative_bounding_box
                    h, w, _ = image_bgr.shape
                    x1 = int(bbox.xmin * w)
                    y1 = int(bbox.ymin * h)
                    x2 = int((bbox.xmin + bbox.width) * w)
                    y2 = int((bbox.ymin + bbox.height) * h)

                    face_crop = image_bgr[max(0, y1):min(h, y2), max(0, x1):min(w, x2)]

                    if face_crop.size == 0 or face_crop.shape[0] < 30 or face_crop.shape[1] < 30:
                        print("âš ï¸ ê°ì • ì¶”ë¡  ê±´ë„ˆëœ€: ì–¼êµ´ ì˜ì—­ì´ ë„ˆë¬´ ì‘ìŒ")
                        logger.log("unclassified")
                        continue

                    try:
                        face_gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)
                        emotion = predict_emotion(face_gray)
                        korean_label = emotion_to_korean(emotion)

                        # âœ… ê°ì • ì¹´ìš´íŠ¸ (ë¡œì»¬)
                        emotion_counter[korean_label] += 1

                        # âœ… ì–¼êµ´ ìœ„ì— ê°ì • ë¼ë²¨ í‘œì‹œ (í•œê¸€)
                        draw.text((x1, y1 - 30), korean_label, font=font, fill=(0, 255, 0))

                        # âœ… ê°ì • ë¡œê¹…
                        logger.log(emotion)

                        # âœ… C++ë¡œ ê°ì • ì „ë‹¬
                        send_emotion_to_cpp(emotion)

                    except Exception as e:
                        print(f"âš ï¸ ê°ì • ì¶”ë¡  ì‹¤íŒ¨: {e}")
                        traceback.print_exc()
                        logger.log("unclassified")

            # âœ… ì˜ìƒ ì¢Œì¸¡ ìƒë‹¨: ë°˜íˆ¬ëª… ê°ì • í†µê³„ í‘œì‹œ
            stats_str = get_emotion_stats_from_cpp()
            stats_lines = stats_str.strip().splitlines()
            overlay_width = 280
            overlay_height = 40 + len(stats_lines) * 35
            draw.rectangle([(10, 10), (10 + overlay_width, 10 + overlay_height)], fill=(0, 0, 0, 180))

            draw.text((20, 20), "ê°ì • í†µê³„ (C++)", font=font, fill=(255, 255, 0))
            for i, line in enumerate(stats_lines):
                draw.text((20, 60 + i * 30), line, font=font, fill=(200, 200, 200))

            image_bgr = np.array(image_pil)
            cv2.imshow("Face Detection + Emotion", image_bgr)

            # âœ… í‚¤ ì…ë ¥ ì²˜ë¦¬
            key = cv2.waitKey(5) & 0xFF
            if key == 27:  # ESC
                break
            elif key == ord('s'):
                print("\nğŸ“Š [C++] ê°ì • í†µê³„")
                print(stats_str, end="") 
                stats_dict = parse_emotion_stats(stats_str)
                plot_emotion_bar_chart(stats_dict)
            elif key == ord('r'):
                reset_cpp_stats()
                print("ğŸ” ê°ì • í†µê³„ ì´ˆê¸°í™”ë¨")
            elif key == ord('t'):
                print("ğŸ“ˆ ê°ì • ë³€í™” íŠ¸ë Œë“œ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ëŠ” ì¤‘...")
                latest_csv = get_latest_log_file()
                if latest_csv:
                    print(f"ğŸ“ ì‚¬ìš© ë¡œê·¸ íŒŒì¼: {latest_csv}")
                    plot_emotion_trend(latest_csv)
                else:
                    print("âš ï¸ ë¡œê·¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        cap.release()
        cv2.destroyAllWindows()

# ê°ì • ì½”ë“œ â†’ í•œê¸€ ë³€í™˜ í•¨ìˆ˜
def emotion_to_korean(emotion: str) -> str:
    return {
        "angry": "í™”ë‚¨",
        "disgust": "ì—­ê²¨ì›€",
        "fear": "ê³µí¬",
        "happy": "ê¸°ì¨",
        "neutral": "ì¤‘ë¦½",
        "sad": "ìŠ¬í””",
        "surprise": "ë†€ëŒ",
        "unclassified": "ë¶„ë¥˜ë¶ˆê°€"
    }.get(emotion, "ì•Œìˆ˜ì—†ìŒ")

def parse_emotion_stats(stats_str: str) -> dict:
    stats = {}
    lines = stats_str.strip().splitlines()
    for line in lines:
        if ':' in line:
            emotion, count = line.split(':')
            stats[emotion.strip()] = int(count.strip())
    return stats

def get_latest_log_file():
    log_files = glob.glob("logs/emotion_log_*.csv")
    if not log_files:
        return None
    return max(log_files, key=os.path.getmtime)

if __name__ == "__main__":
    run_face_detection()
